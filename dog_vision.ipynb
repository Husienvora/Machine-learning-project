{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dog-vision.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "QPR8xhhWTq1_"
      ],
      "mount_file_id": "1V41d-ia-1hnPkP42JozctWpUnAXsxZrQ",
      "authorship_tag": "ABX9TyN0C51SoF3aejY3tRJWHgAF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Husienvora/Machine-learning-project/blob/main/dog_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üê∂ End-to-end Multi-class Dog breed Classification\n",
        "\n",
        "This notebook builds an end-to-end multi-class image classifier using tensorFlow 2.0 and tensorflow Hub.\n",
        "\n",
        "##1.Problem\n",
        "\n",
        "Identifying the breed of a dog given an image of the dog\n",
        "\n",
        "### A Scenario\n",
        "Suppose i am sitting in a park and take a photo of a dog of which i want to know the breed of, I will be in need of this model then.\n",
        "\n",
        "##2. Data\n",
        "The data we're using is from Kaggle's dog breed identification competition.\n",
        "\n",
        "https://www.kaggle.com/c/dog-breed-identification/overview\n",
        "\n",
        "## 3 .Evaluation \n",
        "The evaluation is a file for each dog breed of each test image.\n",
        "\n",
        "https://www.kaggle.com/c/dog-breed-identification/overview/evaluation\n",
        "\n",
        "##4.Features\n",
        "\n",
        "Some infromation about the data \n",
        "* We're dealing with images(unstructured data) so it's probably best we use deep learning/transfer learning.\n",
        "\n",
        "* There are 120 breeds of dogs (this means there are 120 different classes).\n",
        "\n",
        "* There are around 10000+ images in the trainning set(these images have labels)\n",
        "\n",
        "* There are around 10,000+ images in the test set (these images have no labels ,because we'll want to predict them)."
      ],
      "metadata": {
        "id": "Hw_NZYHgcfC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TCDekAeHetZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Unzip the data.\n",
        "##!unzip \"drive/MyDrive/Dogvision/dog-breed-identification.zip\" -d \"drive/MyDrive/Dogvision\""
      ],
      "metadata": {
        "id": "azIzirwZc5Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "za2fkWIGiQlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get our workspace ready\n",
        "\n",
        "* Import TensorFlow 2.x --Done\n",
        "* Import TensorFLow Hub --Done\n",
        "* Make sure we're using a GPU --Done\n"
      ],
      "metadata": {
        "id": "U5xwlVaZiRvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary tools\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "print(\"TF version\",tf.__version__)\n",
        "print(\"TF version\",hub.__version__)\n",
        "\n",
        "#Check for gpu availability \n",
        "print(\"GPU\",\"available(yesss!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available\")\n",
        "\n"
      ],
      "metadata": {
        "id": "iXBt9lNfhtDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting our data ready (Turnin it into tensors)\n",
        "\n",
        "## With all machine learning models our data and to be in numerical format so that's what we wiil be doing first turning our iages into tensors(Numerical representation).\n"
      ],
      "metadata": {
        "id": "RsVxEXd6ikO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checkout the labels of our data\n",
        "import pandas as pd\n",
        "\n",
        "labels_csv=pd.read_csv(\"drive/MyDrive/Dogvision/labels.csv\")\n",
        "print(labels_csv.describe())\n",
        "print(labels_csv.head())"
      ],
      "metadata": {
        "id": "hIY-2QgRjgAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_labels_csv=pd.DataFrame({\"id\":labels_csv[\"id\"],\"Breeds\":labels_csv[\"breed\"]})\n",
        "dataframe_labels_csv"
      ],
      "metadata": {
        "id": "kS_i4zcqmkmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#How many images are there of each breed \n",
        "labels_csv[\"breed\"].value_counts().plot.bar(figsize=(20,10))"
      ],
      "metadata": {
        "id": "IqerqpYBj9Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv[\"breed\"].value_counts().median()"
      ],
      "metadata": {
        "id": "QPxSt09ikpYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's view an image\n",
        "from IPython.display import Image\n",
        "Image(\"drive/MyDrive/Dogvision/train/fff43b07992508bc822f33d8ffd902ae.jpg\")"
      ],
      "metadata": {
        "id": "uHJJX0S6lSol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting images and their labels\n",
        "Let's get a list of all our image file pathnames\n",
        "\n"
      ],
      "metadata": {
        "id": "MtO8fgOJoZ18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_labels_csv"
      ],
      "metadata": {
        "id": "-ZjXpWRZpJ27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames=[\"drive/MyDrive/Dogvision/train/\"+fname +\".jpg\" for fname in dataframe_labels_csv[\"id\"]]\n",
        "\n",
        "#Check the first 10\n",
        "filenames"
      ],
      "metadata": {
        "id": "Chtu6QvGpOYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check wether number of file names matches number of actual image files\n",
        "import os\n",
        "if (len(os.listdir(\"drive/MyDrive/Dogvision/train/\"))==len(filenames)):\n",
        "  print(\"All the files matched ..proceed\")\n",
        "else:\n",
        "\n",
        "  print(\"Check the directory for issues\")  "
      ],
      "metadata": {
        "id": "u1SLSaHapX_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#One more check\n",
        "Image(filenames[9000])"
      ],
      "metadata": {
        "id": "vNSlz9HHq9N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv[\"breed\"][9000]"
      ],
      "metadata": {
        "id": "natyE9-NsEXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we've image filepaths in a list lets prepare our labels"
      ],
      "metadata": {
        "id": "lvhoMfY7sLPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "labels=labels_csv[\"breed\"].to_numpy()\n",
        "labels"
      ],
      "metadata": {
        "id": "JU-yj1qysq9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "metadata": {
        "id": "MZyfxZOTs3s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#See if number of labels matches number of filenames\n",
        "\n",
        "if (len(labels)==len(filenames)):\n",
        "  print(\"Number of labels matches number of filenames\")\n",
        "else:\n",
        "  print(\"Number of labels does not match number of filenames .check the data directories\")\n"
      ],
      "metadata": {
        "id": "g9pVTZUHs6bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the unique label values\n",
        "unique_breeds=np.unique(labels)\n",
        "unique_breeds"
      ],
      "metadata": {
        "id": "FxH92Gb1tfbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(unique_breeds)"
      ],
      "metadata": {
        "id": "_9N2QRZmuXz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a single label into an array of booleans\n",
        "#FOR EG-\n",
        "print(labels[3])\n",
        "labels[3]==unique_breeds\n"
      ],
      "metadata": {
        "id": "aFTQaXuhud-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Turn every label int a boolean array\n",
        "boolean_labels=[label==unique_breeds for label in labels]\n",
        "boolean_labels[:3]"
      ],
      "metadata": {
        "id": "IOR9870tvRRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(boolean_labels)"
      ],
      "metadata": {
        "id": "XbjiAmoDvIwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example turning boolean array into integers\n",
        "\n",
        "print(labels[0])#Original label\n",
        "print(np.where(unique_breeds==labels[0])) # index where label occurs\n",
        "print(boolean_labels[0].argmax()) # index where label occurs in boolean array\n",
        "print(boolean_labels[0].astype(int)) # there will be a 1 where the sample label occurs"
      ],
      "metadata": {
        "id": "WuxA9YuwwPvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creatinng our own validation set\n",
        "Since the dataset from kaggle doesn't come with a validation set ,we're going to create our own\n"
      ],
      "metadata": {
        "id": "y2zH7Ex40sOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup X & y variabels\n",
        "x=filenames\n",
        "y=boolean_labels\n"
      ],
      "metadata": {
        "id": "ywtZWyuT7CcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(filenames)"
      ],
      "metadata": {
        "id": "yYWbHs7arAW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're goin to start off experimenting with ~1000 image and increase as needed\n"
      ],
      "metadata": {
        "id": "Up_Mi_A1rB3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set number of images to use for experimenting \n",
        "NUM_IMAGES=1000 #@param {type:\"slider\",min:1000, max:10000}"
      ],
      "metadata": {
        "id": "NmsiJgnurR9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's split our data into train and validation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "#split them into trainning and validation of total size NUM_IMAGES\n",
        "X_train,X_val,y_train,y_val=train_test_split(x[:NUM_IMAGES],\n",
        "                                             y[:NUM_IMAGES],\n",
        "                                             test_size=0.2,\n",
        "                                             random_state=42)\n",
        "len(X_train),len(y_train),len(X_val),len(y_val)\n"
      ],
      "metadata": {
        "id": "kEufOsVRrouj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a peek at the training data"
      ],
      "metadata": {
        "id": "iq_jA4S_sx6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image('drive/MyDrive/Dogvision/train/00bee065dcec471f26394855c5c2f3de.jpg')"
      ],
      "metadata": {
        "id": "TqD39ws7vZTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "unique_breeds[y_train[0].argmax()]\n"
      ],
      "metadata": {
        "id": "kaLwOwhMtX7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0],y_train[0]"
      ],
      "metadata": {
        "id": "1ei3QGgItqWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Images (Turning images into tensors)\n",
        "\n",
        "To preprocesss out images into tensors we're going to write a function whic does a this things:\n",
        "\n",
        "   1. Take an image filepath as input\n",
        "   2. Use TensorFlow to read the file and save it to a variable,image\n",
        "   3. Turn our image (a jpg)into tensors\n",
        "   4. Normalize our image (convert color channel value from 0-255 to 0-1\n",
        "   5. Resize the image to be a shape of (224,224)\n",
        "   6. Return the modified image\n",
        "\n",
        "Before we do,let's see what importing an image looks like"
      ],
      "metadata": {
        "id": "V9VUtxsctwcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert image to numpy array\n",
        "from matplotlib.pyplot import imread\n",
        "image=imread(filenames[42])\n",
        "image.shape\n",
        "\n"
      ],
      "metadata": {
        "id": "uVoTxY2OuXXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.max(),image.min()"
      ],
      "metadata": {
        "id": "ObtlbcwE02Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image[:2]"
      ],
      "metadata": {
        "id": "NauvcW4j1VZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant(image)[:2]"
      ],
      "metadata": {
        "id": "Xf8b3xqa1JlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define image size\n",
        "IMG_SIZE=224\n",
        "\n",
        "#Create a function for prerocessing images\n",
        "def process_image(image_path,img_size=IMG_SIZE):\n",
        "  \"\"\"\n",
        "  Takes an image file path and turns the image into tensor\n",
        "  \n",
        "  \"\"\"\n",
        "  # Read in an image file \n",
        "  image=tf.io.read_file(image_path)\n",
        "  #Turn the jpeg image into numerical tensors with 3 colour channels(Red,green,Blue)\n",
        "  image=tf.image.decode_jpeg(image,channels=3)\n",
        "  #Convert te color channels values from 0 to 255 to 0 to 1 values\n",
        "  image=tf.image.convert_image_dtype(image,tf.float32)\n",
        "  # Resize the image to our desired value(244,244)\n",
        "  image=tf.image.resize(image,size=[IMG_SIZE,IMG_SIZE])\n",
        "\n",
        "  return image\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VLCWbD2l1K4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turning our data into batches\n",
        "\n",
        "Why turn our data into batches?\n",
        "\n",
        "Let's say you're trying to process 10,000+ image in one \n",
        "go...they all might not fit into memory.\n",
        "\n",
        "So that's why we do about 32 (this is the batch size) images at a time (you can manually adjust the batch size if need be).\n",
        "\n",
        "In order to use Tesnorflow effectively ,we need our data in te form of Tensor tupels which look like this:\n",
        "`(image,label)`\n",
        "\n"
      ],
      "metadata": {
        "id": "fW3N9qFwnKyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a simple function to return a tuple (image,label)\n",
        "\n",
        "def get_image_label(image_path,label):\n",
        "  \"\"\"\n",
        "  Takes an image path name and the associated label,\n",
        "  processes the image and return a type of (image,label).\n",
        "  \"\"\"\n",
        "  image=process_image(image_path)\n",
        "  return image, label\n",
        "  "
      ],
      "metadata": {
        "id": "9_K8S8dzq9iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_image_label(x[42],tf.constant(y[42]))"
      ],
      "metadata": {
        "id": "_7ZjcpYZsfQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got a way to turn our data into tupels of tensors in the form:`(image,label)`.Let's make a function to turn all of our data(x&y) into batches!\n",
        "\n"
      ],
      "metadata": {
        "id": "XEyeA7xVuSKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the batch size ,32 is a good start\n",
        "BATCH_SIZE=32\n",
        "\n",
        "#Create a function to turn data into batches\n",
        "def create_data_batches(X,y=None,batch_size=BATCH_SIZE,valid_data=False,test_data=False):\n",
        "  \"\"\"\n",
        "  Create batches of data out of image(X) and label (y) pairs.\n",
        "  Shuffels the data if it's training data bur doesn't shuffle if it's validation data.\n",
        "  Also accepts test data as input (no labels is set to default value false because test data does not contain labels since we're going to predict those.)\n",
        "  test data is set to false when batches of training data are being made and set to true when batches of test data are being made.\n",
        "  \"\"\"\n",
        "  # If the data is a test dataset ,we probably don't have labels\n",
        "  if test_data:\n",
        "    print(\"Creating test data batches..\")\n",
        "    data=tf.data.Dataset.from_tensor_slices((tf.constant(X))) #Only filepaths (no labels)\n",
        "    data_batch=data.map(process_image).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  # if the data is a valid dataset  ,we don't need to shuffle it\n",
        "  elif valid_data:\n",
        "    print(\"Creating validation data batches..\")\n",
        "    data=tf.data.Dataset.from_tensor_slices((tf.constant(X),tf.constant(y))) #(Filepaths,labels)\n",
        "    data_batch=data.map(get_image_label).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  else:\n",
        "    print(\"Creating training data batches..\")\n",
        "    #Turn fileapths and labels into Tensors\n",
        "    data=tf.data.Dataset.from_tensor_slices((tf.constant(X),tf.constant(y)))\n",
        "\n",
        "    #Shuffling pathnames and labels before mapping images processor function is faster than shuffling images\n",
        "    data =data.shuffle(buffer_size=len(X))\n",
        "\n",
        "    # Create (image,label) tuples (this also turns the iamge path into a preprocessed image)\n",
        "    data=data.map(get_image_label)\n",
        "\n",
        "    #Turn the training data into batches \n",
        "    data_batch=data.batch(BATCH_SIZE)\n",
        "\n",
        "  return data_batch   \n",
        "\n",
        "  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9wMvznavvqW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Warf1Hnvqcty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create training and validation data batches\n",
        "train_data=create_data_batches(X_train,y_train)\n",
        "val_data=create_data_batches(X_val,y_val,valid_data=True)"
      ],
      "metadata": {
        "id": "SnMzatC3QSxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "849DstO3yIhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check out the different attributes of our data batches\n",
        "train_data.element_spec,val_data.element_spec"
      ],
      "metadata": {
        "id": "ypQnoOg6Gp1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualizing Data batches\n",
        "\n",
        "Our data is now in batches ,however these can be a little hard ot understand/comprehend,let's visualize them!"
      ],
      "metadata": {
        "id": "RSLGPxmLfsDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#Create a function for viewing images in a data batch\n",
        "def show_25_images (images,labels):\n",
        "  \"\"\"\n",
        "  Displays a plot of 25 images and their labels from a data batch\n",
        "  \"\"\"\n",
        "  #Setup the figure \n",
        "  plt.figure(figsize=(10,10))\n",
        "  #Loop through 25 (for displaying 25 images)\n",
        "  for i in range(25):\n",
        "    #Create subplots (5 rows,5columns)\n",
        "    ax=plt.subplot(5,5,i+1)\n",
        "    #Display an image\n",
        "    plt.imshow(images[i])\n",
        "    #Add the iamge label as the title\n",
        "    plt.title(unique_breeds[labels[i].argmax()])\n",
        "    #Turn the grid lines off\n",
        "    plt.axis(\"off\")\n",
        " "
      ],
      "metadata": {
        "id": "MWs07uplkPg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_images,train_labels=next(train_data.as_numpy_iterator())\n",
        "\n",
        "\n",
        "plt.imshow(train_images[0]),unique_breeds[train_labels[0].argmax()] \n",
        "\n"
      ],
      "metadata": {
        "id": "VP3FZazgloiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bJzzgfNrzRjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let's visualize our data in a training batch\n",
        "show_25_images(train_images,train_labels)"
      ],
      "metadata": {
        "id": "QrDukw3bkc9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a model \n",
        "\n",
        "Before we build a model ,there are a few things we need to define:\n",
        "* The input shape (our images shape,in the form of Tensors) to uor model.\n",
        "* THe output shape (image labelsmin the form of Tensors )of our model\n",
        "*The URL of the model we want to use from Tesnorflow hub -https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4."
      ],
      "metadata": {
        "id": "z_-yMfv3nDkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup input shape to the model\n",
        "INPUT_SHAPE=[None,IMG_SIZE,IMG_SIZE,3] #batch,height,heightwidthmcoour channels\n",
        "#Setup output shape of our model\n",
        "OUTPUT_SHAPE=len(unique_breeds)\n",
        "\n",
        "#Setup model URL from TensorFlow Hub\n",
        "MODEL_URL= \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\"\n"
      ],
      "metadata": {
        "id": "U_UlwO_8402h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have got our inputs ,outputs and model ready to go\n",
        "Let's put them together into a keras deep learning model\n",
        "\n",
        "Knowing this,let's create a function which \n",
        "* Takes the input shape ,output shape and the model we've chosen as parameters\n",
        "* Defines the layers in keras model in sequential fashion (do this first,then this,then that).\n",
        "* Compiles the model (says how it should be evaluated and improved)\n",
        "* Build the model (tells the model the input shape it'll be getting).\n",
        "* Returns the model.\n",
        "\n",
        "All of these steps can be found here:https://www.tensorflow.org/guide/keras/sequential_model"
      ],
      "metadata": {
        "id": "BwgvfGlsVniu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a function which builds a keras model\n",
        "def create_model(input_shape=INPUT_SHAPE,output_shape=OUTPUT_SHAPE,model_url=MODEL_URL):\n",
        "  print(\"Building model with:\",MODEL_URL)\n",
        "\n",
        "  #Setup the model layers\n",
        "  model=tf.keras.Sequential([hub.KerasLayer(MODEL_URL),\n",
        "                             tf.keras.layers.Dense(units=OUTPUT_SHAPE,\n",
        "                                                   activation=\"softmax\")\n",
        "  ])\n",
        "  \n",
        "\n",
        "\n",
        "  #Compile the model\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "      optimizer=tf.keras.optimizers.Adam(),\n",
        "      metrics=[\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  # Build the model\n",
        "  model.build(INPUT_SHAPE)\n",
        "\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "MlkTCfgKXILJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "9mQRcxIsfNbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating callbacks\n",
        "\n",
        "Callbacks are helper function a model can use during training to do such things as save its progress,check its progress or stop training early if a model stops improving.\n",
        "\n",
        "\n",
        "we'll createa two callbacks one for tesnorboard which helps track our models progress and another for early stopping\n",
        "which prevents our model from training too long.\n",
        "\n",
        "##TensorBoard callback\n",
        "\n",
        "To setup a Tensorboard callback,we need to do 3 things \n",
        "1. load the Tensorboard notebook extension ‚úî\n",
        "2. Create a Tesnorboard callback which is able to save logs ‚úî\n",
        "3. Visualize our models training logs with `%tensorboard` magic function (we'll do this after model trainning)"
      ],
      "metadata": {
        "id": "qiy3mwVnfWLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Tensorboard notebook extension\n",
        "%load_ext tensorboard\n"
      ],
      "metadata": {
        "id": "cFMdCGv8xyMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "#Create a function to build a Tensorboard callback\n",
        "def create_tensorboard_callback():\n",
        "  # Create a log directory for storing tensorflow logs\n",
        "  logdir=os.path.join(\"drive/MyDrive/Dogvision/logs\",\n",
        "                      datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  return tf.keras.callbacks.TensorBoard(logdir)\n"
      ],
      "metadata": {
        "id": "Si1HX2A1y5Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Early Stopping callback\n",
        "\n",
        "Early stopping helps stop our model from overfitting by stopping training if a certain evaluation metric stops imporving"
      ],
      "metadata": {
        "id": "gtKuKKWZ53Th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create early stopping callback\n",
        "early_stopping=tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                patience=3)\n"
      ],
      "metadata": {
        "id": "ESvIPgiPAFjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a model (on subset of data)\n",
        "\n",
        "Our first model is only going to train on 1000 images,to make sure everything is working"
      ],
      "metadata": {
        "id": "UUqKiMbTAn94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS =100 #@param {type:\"slider\",min:10,max:110,step:10}"
      ],
      "metadata": {
        "id": "d-q2dIt8EWjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check to make sure we're still running on a gpu\n",
        "print('GPU',\"available(yes)\" if tf.config.list_physical_devices(\"GPU\") else \"not available\")"
      ],
      "metadata": {
        "id": "IoKzHqm6E1nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a function which trains a model.\n",
        "\n",
        "* Create a model using `create_model()`\n",
        "* Setup a TensorBoard callback using `create_tensorboard_callback()`\n",
        "* Call the fit() function on our model passing it the training data,number of epochs to train for (`NUM_EPOCHS`) and the callbacks we'd like to use\n",
        "*Return the model \n"
      ],
      "metadata": {
        "id": "wHdQz2l9F_WI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Build a function to train and return a trained model\n",
        "def train_model():\n",
        "  \"\"\"\n",
        "  Trains a given model and returns the trained version.\n",
        "  \"\"\"\n",
        "  #Create a model\n",
        "  model=create_model()\n",
        "\n",
        "  #Create new Tensorboard session everytime we train our model\n",
        "  tensorboard = create_tensorboard_callback()\n",
        "  \n",
        "  #Fit the model to the data passing it the callbacks we created\n",
        "  model.fit(x=train_data,\n",
        "            epochs=NUM_EPOCHS,\n",
        "            validation_data=val_data,\n",
        "            validation_freq=1,\n",
        "            callbacks=[tensorboard,early_stopping])\n",
        "  #Return the fitted model\n",
        "  return model"
      ],
      "metadata": {
        "id": "oraJFZzHIsJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model=train_model()"
      ],
      "metadata": {
        "id": "Q6Q6zcDcJRNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the tensorboard logs\n",
        "\n",
        "The tensorboard magic function (`%tensorboard`) will access the logs directory we created early and visualize it's contents"
      ],
      "metadata": {
        "id": "QPR8xhhWTq1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir drive/MyDrive/Dogvision/logs"
      ],
      "metadata": {
        "id": "8OO3ZCaMUAPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making and evaluating prediction using a trained model\n"
      ],
      "metadata": {
        "id": "RHR4ObnUUSVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Make prediction on the validation data (not used to train on)\n",
        "predictions=model.predict(val_data,verbose=1)\n",
        "predictions"
      ],
      "metadata": {
        "id": "RZJKIk_4OGRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "metadata": {
        "id": "_y2SUjjzOhXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_val)"
      ],
      "metadata": {
        "id": "QhWrgs42Onqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(unique_breeds)"
      ],
      "metadata": {
        "id": "noqfn4psOp0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(predictions[0])"
      ],
      "metadata": {
        "id": "9JXbEKw7OwtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#First prediction\n",
        "index=81\n",
        "print(predictions[index])\n",
        "print(f\"Max value (probability of prediction):{np.max(predictions[index])}\")\n",
        "print(f\"Sum:{np.sum(predictions[index])}\")\n",
        "print(f\"Max index:{np.argmax(predictions[index])}\")\n",
        "print(f\"Predicted label:{unique_breeds[np.argmax(predictions[index])]}\")"
      ],
      "metadata": {
        "id": "8dLgtCNmQDKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_breeds[37]"
      ],
      "metadata": {
        "id": "mSd1EQU1R4cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having the above functionality is great but we want to be able to do it at scale.\n",
        "\n",
        "And it would be even better if we could see the image the predictions is being made on !\n",
        "\n",
        "**Note!** prediction probabilities as confidence levels\n",
        "\n"
      ],
      "metadata": {
        "id": "JGmbKsJCSV_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Turn prediction probabilities into their respective label (easier to understand)\n",
        "def get_pred_label(prediction_probabilities):\n",
        "  \"\"\"\n",
        "  Turn an array of prediction probabilites into a label\n",
        "  \"\"\"\n",
        "  return unique_breeds[np.argmax(prediction_probabilities)]\n",
        "\n",
        "#Get a predicted label based on array of prediction probabilities\n",
        "##pred_label=get_pred_label(predictions[81])\n",
        "#pred_label  \n"
      ],
      "metadata": {
        "id": "dddBp1kRUCDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now since our validation data is still in a batch dataset ,we'll have to unbatchify it to make predictions on the validation images and then compare those predictions to the validation labels(truth labels)."
      ],
      "metadata": {
        "id": "J5TwKUROW5Ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_data"
      ],
      "metadata": {
        "id": "na9iXxuaVjxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_=[]\n",
        "labels_=[]\n",
        "\n",
        "#Loop through ubatched data\n",
        "for image,label in val_data.unbatch().as_numpy_iterator():\n",
        "  images_.append(image)\n",
        "  labels_.append(label)\n",
        "  \n",
        "images_[0],labels_[0]"
      ],
      "metadata": {
        "id": "o0cuIvzTYbFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_pred_label(labels_[0])"
      ],
      "metadata": {
        "id": "tO4FR0fhZMm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_pred_label(predictions[0])"
      ],
      "metadata": {
        "id": "8WUFbHbtZZWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4rvba7vuZdG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a function to unlock a batch dataset\n",
        "def unbatchify(data):\n",
        "  \"\"\"\n",
        "  Takes a batched dataset if (image,label) Tensors and returns seperate arrays\n",
        "  of images and labels\n",
        "  \"\"\"\n",
        "\n",
        "  images=[]\n",
        "  labels=[]\n",
        "\n",
        "  #Loop through unbatched data\n",
        "  for image,label in data.unbatch().as_numpy_iterator():\n",
        "    images.append(image)\n",
        "    labels.append(unique_breeds[np.argmax(label)])\n",
        "  return images,labels\n",
        "\n",
        "#Unbatchify the validation data\n",
        "val_images,val_labels=unbatchify(val_data)\n",
        "val_images[0],val_labels[0]\n",
        "\n"
      ],
      "metadata": {
        "id": "WvodJRzVWu5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_pred_label(val_labels[0])"
      ],
      "metadata": {
        "id": "flBeJ5qYbt7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got ways to get :\n",
        "* Prediction labels\n",
        "* Validation labels (truth labels)\n",
        "* Validation images\n",
        "\n",
        "Let's make some function to make these all a bit more visual\n",
        "\n",
        "We'll create a function which:\n",
        "* Takes an array of prediction probabilities ,an array of truth labels and as array of images and integers ‚úî\n",
        "* Convert the prediction probabilites to a predicted label.‚úî\n",
        "* Plot the predicted label,its predicted probability ,the truth label and the target image on single plot.‚úî"
      ],
      "metadata": {
        "id": "Z6sNlxUtevpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pred (prediction_probabilities,labels,images,n=77):\n",
        "  \"\"\"\n",
        "  View the prediction ,ground truth and image for sample n\n",
        "  \"\"\"\n",
        "  pred_prob,true_label,image=prediction_probabilities[n],labels[n],images[n]\n",
        "\n",
        "  #Get the pred label\n",
        "  pred_label=get_pred_label(pred_prob)\n",
        "\n",
        "  #Plot image & remove ticks\n",
        "  plt.imshow(image)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  \n",
        "  #Change the colour of the title depending on if te predictions is right or wrong\n",
        "  if pred_label==true_label:\n",
        "    color=\"green\"\n",
        "  else:\n",
        "    color=\"red\"  \n",
        "  # Change plot title to be predicted ,probability of prediction and truth label\n",
        "  plt.title(\"{} {:2.0f}% {}\".format(pred_label,\n",
        "                                    np.max(pred_prob)*100,\n",
        "                                    true_label),color=color)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "skNuKRv3fJeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pred(prediction_probabilities=predictions,labels=val_labels,images=val_images)"
      ],
      "metadata": {
        "id": "W8ZX-cXhhuIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got one function to visualize our model top prodection ,let's make another t oview our models top 10 predictions\n",
        "\n",
        "This function will:\n",
        "* Take an input of prediction probabilities array and a ground truth array and an integer\n",
        "\n",
        "* Find the top 10:\n",
        " * Prediction probabilites indexes\n",
        " * Prediction probabilities values\n",
        " * Prediction labels\n",
        "\n",
        "*  Plot the top 10 prediction probabilities values and labels ,coloring the true label green\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G8mxlZgrjPK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pred_conf(prediction_probabilities,labels ,n=1):\n",
        "  \"\"\"\n",
        "  plus the top highest predictions confidence along with the truth label for sample n\n",
        "\n",
        "  \"\"\"\n",
        "  pred_prob,true_label=prediction_probabilities[n],labels[n]\n",
        "\n",
        "  #Get the pred label\n",
        "  pred_label=get_pred_label(pred_prob)\n",
        "\n",
        "  #Find the top 10 prediction confidence indexes\n",
        "  top_10_pred_indexes=pred_prob.argsort()[-10:][::-1]\n",
        "  \n",
        "  #Find the top 10 prediction confidence values\n",
        "  top_10_pred_values=pred_prob[top_10_pred_indexes]\n",
        "\n",
        "  #Find the top 10 prediction labels\n",
        "  top_10_pred_labels=unique_breeds[top_10_pred_indexes]\n",
        "\n",
        "  #Setup plot\n",
        "  top_plot=plt.bar(np.arange(len(top_10_pred_labels)),\n",
        "                             top_10_pred_values,\n",
        "                             color=\"gray\")\n",
        "  plt.xticks(np.arange(len(top_10_pred_labels)),\n",
        "             labels=top_10_pred_labels,\n",
        "             rotation=\"vertical\")\n",
        "  #Change color of the true label\n",
        "  if np.isin(true_label,top_10_pred_labels):\n",
        "    top_plot[np.argmax(top_10_pred_labels==true_label)].set_color(\"green\")\n",
        "  else:\n",
        "    pass  \n"
      ],
      "metadata": {
        "id": "V8Pj19e9MBJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pred_conf(prediction_probabilities=predictions,\n",
        "               labels=val_labels,n=9)"
      ],
      "metadata": {
        "id": "geEM8R-sZ_tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0][predictions[0].argsort()[-10:][::-1]]"
      ],
      "metadata": {
        "id": "UnDi4jfTMRvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0].max()\n"
      ],
      "metadata": {
        "id": "Nu0RBzw1M-vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got some function to help us visualize our predictions and evaluate our model ,let's check out a few.\n",
        "  "
      ],
      "metadata": {
        "id": "RB3KkCuTNhkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's check out a few predictions and their different values\n",
        "i_multiplier=20\n",
        "num_rows=3\n",
        "num_cols=2\n",
        "num_images=num_rows*num_cols\n",
        "plt.figure(figsize=(10*num_cols,5*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows,2*num_cols,2*i+1)\n",
        "  plot_pred(prediction_probabilities=predictions,\n",
        "            labels=val_labels,\n",
        "            images=val_images,\n",
        "            n=i+i_multiplier)\n",
        "  plt.subplot(num_rows,2*num_cols,2*i+2)\n",
        "  \n",
        "  plot_pred_conf(prediction_probabilities=predictions,labels=val_labels,n=i+i_multiplier)\n",
        "\n",
        "plt.tight_layout(h_pad=1.0)  \n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YhChjTTOn3rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saving and reloading a trained model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LOKUpB3eoUSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to save a model \n",
        "def save_model(model,suffix=None) :\n",
        "  \"\"\"\n",
        "  Saves a given model in a models directory and appends a suffix\n",
        "  \"\"\"\n",
        "  #Create a model directory pathname with current time\n",
        "  modeldir=os.path.join(\"drive/MyDrive/Dogvision/models\",\n",
        "                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n",
        "  model_path=modeldir+\"_\"+suffix+\".h5\" #Save format model\n",
        "  model.save(model_path)\n",
        "  return model_path\n",
        "  "
      ],
      "metadata": {
        "id": "3xmw11lmzsE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a function to load a trained model\n",
        "def load_model(model_path):\n",
        "  \"\"\"\n",
        "  Loads a save mdoel from a specific path\n",
        "  \"\"\"\n",
        "  print(f\"Loading a saved model from:{model_path}\")\n",
        "  model =tf.keras.models.load_model(model_path,\n",
        "                                    custom_objects={\"KerasLayer\":hub.KerasLayer})\n",
        "  return model\n",
        "  "
      ],
      "metadata": {
        "id": "3crYa4BM1seB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "huYgMVUi13gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got functions to save and load a trained model ,let's make sure they work"
      ],
      "metadata": {
        "id": "lqVVW_nU2l4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Save our model trained on 1000 images\n",
        "import datetime\n",
        "save_model(model,suffix=\"1000-images-mobilenetv2-Adam\")"
      ],
      "metadata": {
        "id": "qN04Zw8C2utX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load a trained model\n",
        "loaded_image_model=load_model(\"drive/MyDrive/Dogvision/models/20211229-07151640762106_1000-images-mobilenetv2-Adam.h5\")"
      ],
      "metadata": {
        "id": "1EDn-_SV3EM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the pre-save model\n",
        "model.evaluate(val_data)"
      ],
      "metadata": {
        "id": "4MScQQJU4p8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_image_model.evaluate(val_data)"
      ],
      "metadata": {
        "id": "30oVrUch4wdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training a big dog model üê∂(on the full data)"
      ],
      "metadata": {
        "id": "3e470_e1410Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(x),len(y)\n"
      ],
      "metadata": {
        "id": "PyLb5uKk6VD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "id": "BzjtDcnw6bz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a data batch with full data set\n",
        "full_data = create_data_batches(x,y)"
      ],
      "metadata": {
        "id": "0fkAdV2e6hre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data"
      ],
      "metadata": {
        "id": "V-8QeH3m6-sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a model for full model\n",
        "full_model=create_model()"
      ],
      "metadata": {
        "id": "6Pylkib67A-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create full model callbacks\n",
        "full_model_tensorboard=create_tensorboard_callback()\n",
        "\n",
        "#No validation set when training on all the data ,so we cant monitor validation accuracy\n",
        "full_model_early_stopping=tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",patience=3)\n",
        "\n"
      ],
      "metadata": {
        "id": "V0WLE2527Urd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Running the cell below will take a little while (maybe up to 30 minutes for the first epoch) because the GPU we're using in the runtime has to load all of the images into memory."
      ],
      "metadata": {
        "id": "fDMSmNwG80aA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model to the full data\n",
        "##full_model.fit(x=full_data,\n",
        "              ## callbacks=[full_model_tensorboard,full_model_early_stopping])"
      ],
      "metadata": {
        "id": "wUmce3o28eV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(full_model,suffix=\"full-image-set-mobilenetv2-Adam\")"
      ],
      "metadata": {
        "id": "eIdxqSAz9drV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load in the full model\n",
        "loaded_full_model=load_model(\"drive/MyDrive/Dogvision/models/20211229-07181640762301_full-image-set-mobilenetv2-Adam.h5\")\n"
      ],
      "metadata": {
        "id": "FvXB7jXcGfEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x)"
      ],
      "metadata": {
        "id": "B34v7LOaG0Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Make predictions on the test data\n",
        "\n",
        "Since our model has been train on images in the form of Tensor batches ,to make predicitons on the test data,we'll have to get it into the same format.\n",
        "\n",
        "luckily we created 'create_data_batches()' earlier which can take a list of filenames as input and cover them into Tensor batches\n",
        "\n",
        "To make predictions on the test data ,we'll ,get the test image filenames.\n",
        "* Get the test image filenames ‚úî\n",
        "* Convert the filenames into test data batches using `create_data_batches` and setting the `test_data` parameter to `True` (since the test data doesn't have labels). ‚úî\n",
        "* Make a predictions array by passing the test batches to the `predict()` method called on our model.\n"
      ],
      "metadata": {
        "id": "IuoOj9fmbPcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test image filenames\n",
        "import os\n",
        "test_path =\"/content/drive/MyDrive/Dogvision/test/\"\n",
        "test_filenames=[test_path + fname for fname in os.listdir(test_path)]\n",
        "test_filenames[0]\n"
      ],
      "metadata": {
        "id": "qUH2gjutbnyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_filenames)"
      ],
      "metadata": {
        "id": "j7cqnkLufQdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create test data batch\n",
        "test_data= create_data_batches(test_filenames,test_data=True)"
      ],
      "metadata": {
        "id": "jewvHlm8fgAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data)\n"
      ],
      "metadata": {
        "id": "ken1d3O_fzpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gt3VJ_2Wngbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note** Calling `predict()` on our full data batch using the loaded full model"
      ],
      "metadata": {
        "id": "JnKa91Aug1dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on test data batch using the loaded full model \n",
        "test_predictions =loaded_full_model.predict(test_data,\n",
        "                                            verbose=1)"
      ],
      "metadata": {
        "id": "QN4KrVlygIhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savetxt(\"drive/MyDrive/Dogvision/preds_array.csv\",test_predictions,delimiter=\",\")"
      ],
      "metadata": {
        "id": "033xnY9thFzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions=np.loadtxt(\"drive/MyDrive/Dogvision/preds_array.csv\",delimiter=\",\")"
      ],
      "metadata": {
        "id": "az1bOH6FiCc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_predictions)"
      ],
      "metadata": {
        "id": "lZ7SruOXiSPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions.shape\n"
      ],
      "metadata": {
        "id": "bCXfcGu5kXPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_predictions)"
      ],
      "metadata": {
        "id": "Bjtox8ciiVBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yDmaJ_8MikaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images=[]\n",
        "\n",
        "\n",
        "#Loop through unbatched data\n",
        "for image in test_data.unbatch().as_numpy_iterator():\n",
        "  images.append(image)\n",
        " "
      ],
      "metadata": {
        "id": "aRcDyS1fl0uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(images)"
      ],
      "metadata": {
        "id": "5q-U9rhOl-zE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "def tensor_to_image(tensor):\n",
        "    tensor = tensor*255\n",
        "    tensor = np.array(tensor, dtype=np.uint8)\n",
        "    if np.ndim(tensor)>3:\n",
        "        assert tensor.shape[0] == 1\n",
        "        tensor = tensor[0]\n",
        "    return PIL.Image.fromarray(tensor)"
      ],
      "metadata": {
        "id": "v9ylvIjcrvu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking if the predictions made on test data set are true you can also cross check them by searching the breed on google"
      ],
      "metadata": {
        "id": "NeobNjWHzkHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_to_image(images[10356])"
      ],
      "metadata": {
        "id": "LjZ3oQE_t92I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zA9tPqyvzAMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_breeds[test_predictions[10356].argmax()]"
      ],
      "metadata": {
        "id": "qct6bz0SuDy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making predictions on custom images\n",
        "To make predictions on custom images we'll\n",
        "* Get the filepath of our own images.\n",
        "* Turn the filepaths into data batches using `create_data_batches()`.And since our  custom images wont have labels,we set the `test_data` parameter to `True`.\n",
        "* Pass the custom image data batch to our model's `predict()` method\n",
        "* Convert the predictions output probabilities to predictions labels\n",
        "* Compare the predicted labels to the custom images."
      ],
      "metadata": {
        "id": "MdjackiuuQlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the custom image filepaths\n",
        "custom_path=\"drive/MyDrive/Dogvision/custom-dog-photos/\"\n",
        "custom_image_paths=[custom_path+fname for fname in os.listdir(custom_path) ]"
      ],
      "metadata": {
        "id": "qtSX1YS82eqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_image_paths=custom_image_paths[0:]\n",
        "custom_image_paths\n"
      ],
      "metadata": {
        "id": "SdoNRhZ53aVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Turn custom images into batch data sets\n",
        "custom_data=create_data_batches(custom_image_paths,test_data=True)\n",
        "custom_data\n"
      ],
      "metadata": {
        "id": "F2xxEIDf5F4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make predictions on the custom data\n",
        "custom_preds=loaded_full_model.predict(custom_data)"
      ],
      "metadata": {
        "id": "gtljWmGj5uZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_preds.shape"
      ],
      "metadata": {
        "id": "kII9UHW96FL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_pred_labels=[get_pred_label(custom_preds[i]) for i in range(len(custom_preds))]\n",
        "custom_pred_labels"
      ],
      "metadata": {
        "id": "K7eEHj-x6ZVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images=[]\n",
        "\n",
        "\n",
        "#Loop through unbatched data\n",
        "for image in custom_data.unbatch().as_numpy_iterator():\n",
        "  images.append(image)\n",
        " "
      ],
      "metadata": {
        "id": "PA0pYzXm7cZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_pred_labels[2]"
      ],
      "metadata": {
        "id": "H87BkUW5vxQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_to_image(images[2])"
      ],
      "metadata": {
        "id": "RXWxSdzYvVfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fwS5lQYHvtpt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}